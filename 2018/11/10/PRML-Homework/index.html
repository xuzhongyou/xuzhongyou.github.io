<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">
<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="-MachineLearning -course -homework," />










<meta name="description" content="Purpose 这两周感觉效率偏低，GAN的论文看的迷迷糊糊还没有完全弄清楚，加上最近沉迷吃鸡，没有那个精力，心态（主要原因）去好好整一篇博客。所以…打算换个project来缓一缓断更的节奏。这个project是打算作为模式识别机器学习课程的一篇报告。说起这个课脑袋就很疼，一只脚踏入了挂科的深渊，希望自己能够吸取教训。这个project是kaggle上的一个竞赛，有7万刀。虽然已经结束了内容也比较">
<meta name="keywords" content="-MachineLearning -course -homework">
<meta property="og:type" content="article">
<meta property="og:title" content="PRML-Homework">
<meta property="og:url" content="http://yoursite.com/2018/11/10/PRML-Homework/index.html">
<meta property="og:site_name" content="from Demon import Angel">
<meta property="og:description" content="Purpose 这两周感觉效率偏低，GAN的论文看的迷迷糊糊还没有完全弄清楚，加上最近沉迷吃鸡，没有那个精力，心态（主要原因）去好好整一篇博客。所以…打算换个project来缓一缓断更的节奏。这个project是打算作为模式识别机器学习课程的一篇报告。说起这个课脑袋就很疼，一只脚踏入了挂科的深渊，希望自己能够吸取教训。这个project是kaggle上的一个竞赛，有7万刀。虽然已经结束了内容也比较">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/Bagging.png">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/decision_tree.png">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/tui.png">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/X.png">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/dan.png">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/LDA.PNG">
<meta property="og:image" content="http://yoursite.com/2018/11/10/PRML-Homework/PCA.png">
<meta property="og:updated_time" content="2018-11-26T13:54:40.644Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PRML-Homework">
<meta name="twitter:description" content="Purpose 这两周感觉效率偏低，GAN的论文看的迷迷糊糊还没有完全弄清楚，加上最近沉迷吃鸡，没有那个精力，心态（主要原因）去好好整一篇博客。所以…打算换个project来缓一缓断更的节奏。这个project是打算作为模式识别机器学习课程的一篇报告。说起这个课脑袋就很疼，一只脚踏入了挂科的深渊，希望自己能够吸取教训。这个project是kaggle上的一个竞赛，有7万刀。虽然已经结束了内容也比较">
<meta name="twitter:image" content="http://yoursite.com/2018/11/10/PRML-Homework/Bagging.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/10/PRML-Homework/"/>





  <title>PRML-Homework | from Demon import Angel</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">from Demon import Angel</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">我哽咽道：你是赵默笙，可我不是何以琛啊。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/10/PRML-Homework/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiaokehu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="from Demon import Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">PRML-Homework</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-10T15:23:15+08:00">
                2018-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Project/" itemprop="url" rel="index">
                    <span itemprop="name">-Project</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/11/10/PRML-Homework/" class="leancloud_visitors" data-flag-title="PRML-Homework">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3,911
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  14
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h1><blockquote>
<p>这两周感觉效率偏低，GAN的论文看的迷迷糊糊还没有完全弄清楚，加上最近沉迷吃鸡，没有那个精力，心态（主要原因）去好好整一篇博客。所以…打算换个project来缓一缓断更的节奏。这个project是打算作为模式识别机器学习课程的一篇报告。说起这个课脑袋就很疼，一只脚踏入了挂科的深渊，希望自己能够吸取教训。这个project是kaggle上的一个竞赛，有7万刀。虽然已经结束了内容也比较简单，但应该是一个不错的入门案例。</p>
</blockquote>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="Bagging-and-RandomForest"><a href="#Bagging-and-RandomForest" class="headerlink" title="Bagging and RandomForest"></a>Bagging and RandomForest</h2><p>在机器学习中为了得到强泛化性能的集成，个体学习器应尽可能的相互独立，即基学习器尽可能具有较大的差异。主要的做法是：给定一个训练数据集采样出若干个不同的子集，在子集的基础上训练分类器。需要的注意的是子集的数量不能太小否则无法进行有效的学习，又要满足独立的原则，所以一般使用相互有交叠的采样子集。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><ul>
<li>并行式集成学习方法的一种，假如采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练出基学习器，再将基学习器结合。</li>
<li>Bagging是对分类任务使用简单投票法，对回归使用简单平均法，票数 相同随机选择一个。</li>
<li>Bagging和Adaboost有一个不同的地方，标准Adaboost只适用于二分类任务，Bagging能够不改地用于多分类和回归任务。<br>看下训练算法：<br><img src="/2018/11/10/PRML-Homework/Bagging.png" alt=""><h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><blockquote>
<p>关于决策树算法这块，这边不打算展开叙述（直观理解还是需要例子加以辅助，推荐周志华的西瓜书，浅显易懂）。只说明大体上决策树的组成和重要的知识点。</p>
</blockquote>
</li>
</ul>
<p>做决策的树形模型，一般的，一棵决策树包含一个根节点，若干个内部节点和若干个叶节点。叶节点对应于决策结果，其他结点对应熟悉你个测试，每个结点包含的样本集合根据属性测试的结果被划分到子节点中，根节点包含样本全集。基本思想‘分而治之’，基本思想如下：<br><img src="/2018/11/10/PRML-Homework/decision_tree.png" alt=""></p>
<h4 id="purity"><a href="#purity" class="headerlink" title="purity"></a>purity</h4><p>根据算法可知，构建决策树的重点在于属性的划分。属性的划分依据是结点的纯度，希望决策树的分支结点包含的样本尽可能属于同一类别，即纯度越高越好。纯度有不同的衡量标准：</p>
<h5 id="information-gain"><a href="#information-gain" class="headerlink" title="information gain"></a>information gain</h5><p>information entropy信息熵，信息量的期望，度量样本集合纯度最常用的指标。信息量：事件发生带来的信息大小（一个事件发生的概率越大包含的信息量越少）。对于集合$D$,信息熵的定义为：</p>
<script type="math/tex; mode=display">Ent(D)=-\sum_{k=1}^{|y|}p_klog_2p_k</script><p>$Ent(D)$的值越小，则D的纯度越高。<br>假定离散属性$\alpha$有$V$个可能的取值${\alpha^1,\alpha^2,…,\alpha^V}$,若使用$\alpha$对样本集划分，则会产生$V$个分支结点，其中第$v$个分支结点包含了$D$中所有在属性$\alpha$上取值为$\alpha^v$的样本，记为$D_v$。考虑到不同的分支节点包含的样本数不同，给分支节点赋予权重$\partial{|D^v|}{|D|}$,样本数越多的分支结点的影响越大，则属性$\alpha$对样本集$D$进行划分所获得的信息增益为：</p>
<script type="math/tex; mode=display">Gain(D,\alpha)=Ent(D)-\sum_{v=1}^V\partial{|D^v|}{|D|}Ent(D^v)</script><p>这里信息增益越大，一直意味着按照属性$\alpha$来进行划分所获得的‘纯度提升’越大。那么选择属性的原则按照$\alpha^*=argmax Gain(D,\alpha)$ID3决策树就是按照信息增益为准则来选择划分属性。</p>
<h5 id="gain-ratio"><a href="#gain-ratio" class="headerlink" title="gain ratio"></a>gain ratio</h5><p>刚才说到的信息增益有一个问题，信息增益准则对可取值数目较多的属性有所偏好。大概的理解是 ：每个属性分支结点包含的样本少，则说明纯度大。例如将数据的编号作为划分属性，每个属性分支节点只有一个样本，纯度达到最大，然而这样的决策树泛化能力为0。因此有些决策树使用增益率来选择最有划分属性。如：C4.5。增益率定义为：</p>
<script type="math/tex; mode=display">Gain_ratio(D,\alpha)=\frac{Gain(D,\alpha)}{IV(\alpha)}</script><p>其中</p>
<script type="math/tex; mode=display">IV(\alpha)=-\sum_{v=1}^V\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}</script><p>称为属性$\alpha$的固有值，属性$\alpha$可能取值数目越多（$V$越大），则$IV(\alpha)$的值越大。</p>
<h5 id="gini-index"><a href="#gini-index" class="headerlink" title="gini index"></a>gini index</h5><p>基尼指数是CART决策树。</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
Gini(D) &= \sum_{k=1}^{|y|}\sum_{k^'\neq{k}p_kp_{k'} \\
 &= 1-\sum_{k=1}^{|y|}p_k^2
\end{eqnarray}</script><p>直观上$Gini(D)$表示的意义是：从数据集$D$中随机抽取两个样本，其类别标记不一致的概率，$Gini(D)$越小，则数据集$D$的纯度越高。属性$\alpha$的基尼指数定义为</p>
<script type="math/tex; mode=display">Gini_index(D,\alpha)=\sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)</script><h4 id="pruning"><a href="#pruning" class="headerlink" title="pruning"></a>pruning</h4><p>减枝是决策树学习为了防止过拟合的手段，主要原因是，为了正确分类样本，划分过程不断重复，造成决策分支过多样本学得太好而导致。决策树的减枝基本策略“预减枝”，“后剪枝”。</p>
<ul>
<li>预减枝：在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分布恩那个带来决策树泛化性能提升，则停止划分将该节点标记为叶节点</li>
<li>后剪枝则是先从训练集生成一棵完整的决策树，然后自底而上地对非叶子结点进行考察，若将该结点对一个的子树替换成叶结点能带来决策树泛化性能提升，则将该子树替换成叶节点。<br>上面说的两种减枝方法比较抽象，可以参考周志华的西瓜书，有例子能够更加直观。</li>
</ul>
<h4 id="continuous-values"><a href="#continuous-values" class="headerlink" title="continuous values"></a>continuous values</h4><p>遇到连续属性，应该如何划分属性呢？C4.5采用的是二分法对连续值进行处理。给定样本集$D$,假定$\alpha$在$D$上出现了$n$个不同的取值，将这些值从小到大进行排序，记为${\alpha^1,\alpha^2,…,\alpha^n}$,基于划分点$t$可将$D$分为子集$D_t^-$和$D_t^+$，前者包含属性$\alpha$上取值不大于$t$的样本，后者表示大于$t$的样本。在连续属性$\alpha$上可考察包含$n-1$个元素划分集合：</p>
<script type="math/tex; mode=display">T_a=\{\frac{\alpha_i+\alpha_{i+1}}{2}|1\leq{i}\leq{n-1}\}</script><p>划分后计算划分依据标标准，与其他属性一起比较。需注意的是，于离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。</p>
<h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><ul>
<li>RF是Bagging的一个扩展变体，RF的基学习器是一个决策树。但是RF在Bagginig的基础上，在决策树的训练过程中引入了随机属性选择。</li>
<li>传统decision tree在选择划分属性的原则是当前属性结点的属性集合中选择一个最优属性，在RF中，对每个基决策树的每个结点，从该结点的属性集合中随机选择包含$k$个属性的子集，再从子集中选择一个最优属性用于划分，参$k$控制了随机性的引入程度，推荐是$k=log_2d$。</li>
<li>RF思想简单，容易实现，计算开销小，却有展现除强大的性能。RF对Bagging做了小改动，不仅有来自样本的扰动（Bagging），还有属性的扰动（Decision Tree)这样使得集成的泛化性能可通过个体学习器之间差异度进一步提升。</li>
<li>RF和Bagging的收敛性相似，但是RF的起始性能往往较差，但是随着学习器的数目增多RF能够收敛到更低的泛化误差。</li>
</ul>
<h4 id="combined-strategy"><a href="#combined-strategy" class="headerlink" title="combined strategy"></a>combined strategy</h4><p>学习器的结合策略的好处：</p>
<ul>
<li>统计来说：学习任务的假设空间很大，多个假设在训练数据集上达到同等性能，此时单学习器就会出现弊端，导致泛化性能不佳。</li>
<li>计算来说：学习算法往往会陷入局部极小，局部极小对应的泛化性能差。</li>
<li>表示来说：学习任务假设可能不在当前学习算法假设空间，此时的单学习器无效。<br>常见结合策咯：</li>
<li>平均值：简单平均值，加权平均值</li>
<li>投票法：绝大多数投票法，相对多数投票法，加权投票法</li>
<li>学习法：是通过另一个学习器来进行结合。Stacking是学习法的典型代表。个体学习器称为初级学习器，用于结合的学习器成为次级学习器或元学习器。次级训练数据集不采用初级训练集所用的样本，一般使用交叉验证这样的方式。</li>
</ul>
<h2 id="Liner-model"><a href="#Liner-model" class="headerlink" title="Liner model"></a>Liner model</h2><p>所谓线性模型在给定d个属性描述的示例$x=(x_1;x_2;…x_d)$,通过属性的线性组合来进行预测。</p>
<script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+...+w_dx_d+b</script><p>线性模型虽然简单，但是很多强大的非线性模型是在线性模型的基础上引入层级结构（深度神经网络）和高维映射（SVM等）得到。</p>
<h3 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><p>线性回归是线性模型在回归任务下的一种应用，输出值是一个连续值。线性回归的模型参数就是线性模型的$W,b$,那么如何学习$W,b$呢？需要一个目标函数，使得在$W,b$的作用下，预测值$f(x)$接近真实值$y$，目标函数有很多，在线性回归任务中常用的是<font color="red">均方误差</font></p>
<script type="math/tex; mode=display">
\begin{eqnarray}
(w^*，b^*) &= argmin_{(w,b)}\sum_{i=1}^m(f(x_i)-y_i)^2 \\
&=argmin_{(w,b)}\sum_{i=1}^m(y_i-wx_i-b)^2
\end{eqnarray}</script><p>均方误差对应了欧几里得距离，基于均方误差最小化进行模型求解的方法称为‘最小二乘法’。几何意义：试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。给出目标函数$E_{(w,b)}=\sum_{i=1}^m(y_i-wx_i-b)^2$,该误差函数是关于$w,b$的凸函数，当$w,b$的导数为零时，得到最优解。<br><img src="/2018/11/10/PRML-Homework/tui.png" alt=""><br>更为一般的转为矩阵形式：试图学习</p>
<script type="math/tex; mode=display">f(x_i)=W^Tx_i+b</script><p>继续利用最小二乘法对$w,b$进行估计，为了方便矩阵的直接相乘把$w,b$和在一起$w^T=(w;b)$,相应地把数据集D表示d(属性)+1维的矩阵。<br><img src="/2018/11/10/PRML-Homework/X.png" alt="">新的目标函数为：</p>
<script type="math/tex; mode=display">w^*=argmin_w(y-Xw)^T(y-Xw)</script><p>对$w$求导得到</p>
<script type="math/tex; mode=display">\frac{\partial E_w}{\partial w}=2X^T(Xw-y)</script><p>当$X^TX$为满秩矩阵或正定矩阵时有</p>
<script type="math/tex; mode=display">w_*=(X^TX)^{-1}X^Ty</script><p>但$X^TX$并非时时都是满秩的，这会导致求出多个$w_*$,都能使得均方误差最小化，通常选择哪一个解是由算法的归纳偏好决定的，常见方法引入正则化。<br>除此之外，让线性模型逼近于y的衍生物，实质上时求取输入空间到输出空间的非线性函数映射。如对数线性回归：</p>
<script type="math/tex; mode=display">lny=w^Tx+b</script><p>是让$e^{w^Tx+b}$，更为一般地，考虑单调可微函数$g()$</p>
<script type="math/tex; mode=display">y=g^{-1}(w^Tx+b)</script><p>广义线性模型。</p>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><p>上面说的是线性模型做回归任务，如果是分类任务呢？基于刚才的广义线性模型，只需要找到一个单调可微函数将真实标记$y$和模型预测值$f(x)$联系起来即可。对于二分类输出空间0或1，将上述的线性回归模型$z=w^Tx+b$得到的实值转换到0/1的值，理想的函数是‘单位阶跃函数’。<br><img src="/2018/11/10/PRML-Homework/dan.png" alt="">，但是该函数不连续啊！前人就找到了logistic function。</p>
<script type="math/tex; mode=display">y=\frac{1}{1+e^{-z}}</script><p>sigmoid函数</p>
<script type="math/tex; mode=display">y=\frac{1}{1+e^{-(w^Tx+b)}}</script><p>将该形式转化一下：</p>
<script type="math/tex; mode=display">ln\frac{y}{1-y}=w^Tx+b</script><p>其中$y$可视为样本x作为正例的可能性，$1-y$则视为其反例的可能性，$\frac{y}{1-y}$称为几率，表示$x$作为正例的相对可能性。</p>
<h4 id="Logistic-Regression-Advantage"><a href="#Logistic-Regression-Advantage" class="headerlink" title="Logistic Regression Advantage"></a>Logistic Regression Advantage</h4><ul>
<li>虽然是英文叫Logistic Regression,但是一个分类任务。</li>
<li>该学习器是直接对分类可能性建模，不需要假设数据分布，避免了假设分布不准确的问题。</li>
<li>它不仅预测出类别，而且得到的近似概率预测，这样有助于利用概率辅助决策的任务。</li>
<li>对率函数是任意阶可导的函数，有许多数值优化算法可直接用于求取最优解。</li>
</ul>
<h4 id="Logistic-Regression-and-loglikehood"><a href="#Logistic-Regression-and-loglikehood" class="headerlink" title="Logistic Regression and loglikehood"></a>Logistic Regression and loglikehood</h4><p>将$y$视为后验概率，前式子</p>
<script type="math/tex; mode=display">ln\frac{y}{1-y}</script><p>可转换为</p>
<script type="math/tex; mode=display">ln\frac{p(y=1|x)}{p(y=0|x)}=w^Tx+b</script><p>且有</p>
<script type="math/tex; mode=display">p(y=1|x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}</script><script type="math/tex; mode=display">p(y=0|x)=\frac{1}{1+e^{w^Tx+b}}</script><p>通过‘极大似然法’来估计$w,b$</p>
<script type="math/tex; mode=display">l(w,b)=\sum_{i=1}^mlnp(y_i|x_i;w,b)</script><p>令每个样本属于器真实标记的概率越大越好，进一步将上式中的似然项改写（为了方便$\beta=(w,b),x=(x,1)$）$,则$w^Tx+b$简写为$\beta{^T}x$</p>
<script type="math/tex; mode=display">p(y_i|x_i;w,b)=y_ip_1(x_i,\beta)+(1-y_i)p_0(x_i,\beta)</script><p>是不是有点交叉熵的感觉，留下一个伏笔。</p>
<h2 id="Linear-Discriminant-Analysis"><a href="#Linear-Discriminant-Analysis" class="headerlink" title="Linear Discriminant Analysis"></a>Linear Discriminant Analysis</h2><blockquote>
<p>本来不打算写这个方法的，但是比较简单，那就一笔带过吧。</p>
</blockquote>
<p>LDA不严格的来说就是‘Fisher判别分析’，思想比较简单：给定训练集，设法将样例投影到一条直线（对应二维来说），目标是：同类的投影点尽可能靠近，异类的点尽可能远离。对于测试样本，先投影再根据投影点的位置来确定新样本的类别。如图：<br><img src="/2018/11/10/PRML-Homework/LDA.PNG" alt=""></p>
<h3 id="Math-representation"><a href="#Math-representation" class="headerlink" title="Math representation"></a>Math representation</h3><p>对于数据集$D$，二分类任务为例：有$X_i,\mu_i,\sum_i$分别表示第i类示例的集合，均值向量，协方差矩阵。若将数据投影到直线$w$上，则两类样本的中心在直线上的投影分别为$w_T\mu_0$和$w_T\mu_1$,对于所有样本点投影，样本的协方差分别为$w^T\sum_0w$和$w^T\sum_1w$。上述同类样本点的投影点应该尽可能接近，意味着投影点的协方差尽可能小，即：$w^T\sum_0w+w^T\sum_1w$尽可能小。异类样本投影点尽可能远离，意味着异类中心点之间的距离尽可能大，即$||w_T\mu_0-w_T\mu_1||_2^2$。有了这样的分析，可能到目标函数：</p>
<script type="math/tex; mode=display">J=\frac{||w_T\mu_0-w_T\mu_1||_2^2}{w^T\sum_0w+w^T\sum_1w}</script><p>最大化J即为所求。<br>剩下的一些就是在编程序时减少计算的量的求解，用到的知识：矩阵性质，拉格朗日乘子法，奇异值分解。参考周志华的西瓜书。</p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>占坑</p>
<h1 id="Dimension-reduction"><a href="#Dimension-reduction" class="headerlink" title="Dimension reduction"></a>Dimension reduction</h1><ul>
<li>提供点的坐标进行降维 PCA</li>
<li>点之间的距离矩阵 MDS</li>
</ul>
<h2 id="MDS"><a href="#MDS" class="headerlink" title="MDS"></a>MDS</h2><p>由原始样本的距离矩阵 D 到样本的内积矩阵 B ，然后对 B 进行特征值分解，得到小于等于N个特征值和特征矩阵，构造降维后的样本矩阵 Z。</p>
<h2 id="Linear-Dimension-reduction"><a href="#Linear-Dimension-reduction" class="headerlink" title="Linear Dimension reduction"></a>Linear Dimension reduction</h2><script type="math/tex; mode=display">Z = W^Tx</script><p>$z_i$是原属性向量$x_i$在新坐标系${w_1,w_2,\cdots,w_d}$中的向量坐标。新空间中的属性是原空间属性的线性组合。这是线性降维的基本形式，不同线性降维对低维子空间的性质有不同的要求，相当于对$W$有不同的约束。</p>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><p>Principal Component Analysis 从最近重构性或者最大可分性都能得到主成成分分析的推导。最大可分性：样本点$x_i$在新空间中超平面上的投影是$W_TX_i$,若所有样本点的投影尽可能分来，应使得投影后样本点的方差最大化。投影后的样本方差</p>
<script type="math/tex; mode=display">\sum_iW^Tx_ix_i^TW</script><p>优化函数变为：</p>
<script type="math/tex; mode=display">max_W \quad tr(W^TXX^TW)</script><script type="math/tex; mode=display">s.t. W^TW=I</script><p><img src="/2018/11/10/PRML-Homework/PCA.png" alt=""><br>只需对协方差矩阵$XX^T$进行特征值分解，将求得的特征值排序,再取$d$个特征值对应的特征向量构成$W$,即为主成成分的解。降维后的维度$d$,或者用开销较小的分类器子在交叉验证中选取。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/MachineLearning-course-homework/" rel="tag"># -MachineLearning -course -homework</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/04/Image-Style-Transfer/" rel="next" title="Image_Style_Transfer">
                <i class="fa fa-chevron-left"></i> Image_Style_Transfer
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/21/visualizing-and-understanding-convolutional-networks/" rel="prev" title="visualizing-and-understanding-convolutional-networks">
                visualizing-and-understanding-convolutional-networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>



  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="xiaokehu" />
            
              <p class="site-author-name" itemprop="name">xiaokehu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yourname" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yourname@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Purpose"><span class="nav-number">1.</span> <span class="nav-text">Purpose</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model"><span class="nav-number">2.</span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Bagging-and-RandomForest"><span class="nav-number">2.1.</span> <span class="nav-text">Bagging and RandomForest</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Bagging"><span class="nav-number">2.1.1.</span> <span class="nav-text">Bagging</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Decision-Tree"><span class="nav-number">2.1.2.</span> <span class="nav-text">Decision Tree</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#purity"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">purity</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#information-gain"><span class="nav-number">2.1.2.1.1.</span> <span class="nav-text">information gain</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#gain-ratio"><span class="nav-number">2.1.2.1.2.</span> <span class="nav-text">gain ratio</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#gini-index"><span class="nav-number">2.1.2.1.3.</span> <span class="nav-text">gini index</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#pruning"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">pruning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#continuous-values"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">continuous values</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Random-Forest"><span class="nav-number">2.1.3.</span> <span class="nav-text">Random Forest</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#combined-strategy"><span class="nav-number">2.1.3.1.</span> <span class="nav-text">combined strategy</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Liner-model"><span class="nav-number">2.2.</span> <span class="nav-text">Liner model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Regression"><span class="nav-number">2.2.1.</span> <span class="nav-text">Linear Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic-Regression"><span class="nav-number">2.2.2.</span> <span class="nav-text">Logistic Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Logistic-Regression-Advantage"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">Logistic Regression Advantage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Logistic-Regression-and-loglikehood"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">Logistic Regression and loglikehood</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Discriminant-Analysis"><span class="nav-number">2.3.</span> <span class="nav-text">Linear Discriminant Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Math-representation"><span class="nav-number">2.3.1.</span> <span class="nav-text">Math representation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM"><span class="nav-number">2.4.</span> <span class="nav-text">SVM</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dimension-reduction"><span class="nav-number">3.</span> <span class="nav-text">Dimension reduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MDS"><span class="nav-number">3.1.</span> <span class="nav-text">MDS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Dimension-reduction"><span class="nav-number">3.2.</span> <span class="nav-text">Linear Dimension reduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PCA"><span class="nav-number">3.3.</span> <span class="nav-text">PCA</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaokehu</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">25.0k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>
  


  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  











﻿
  
    

    

  

  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("0Sd2syIyTxcEEmnoSombwfx8-gzGzoHsz", "ijA1IpMh35un7deoLpxjojrh");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  

  

  
  

  
  


  

  

</body>
</html>
